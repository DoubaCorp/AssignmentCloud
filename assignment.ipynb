{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0485891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca167d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data via pandas\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"IMDB_Dataset.csv\")\n",
    "#df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c913da44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=23\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39e4927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text data\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters and punctuation\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = text.split()\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['review'] = df['review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5740a740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one review mention watch oz episod hook right exactli happen first thing struck oz brutal unflinch scene violenc set right word go trust show faint heart timid show pull punch regard drug sex violenc hardcor classic use word call oz nicknam given oswald maximum secur state penitentari focus mainli emerald citi experiment section prison cell glass front face inward privaci high agenda em citi home mani aryan muslim gangsta latino christian italian irish scuffl death stare dodgi deal shadi agreement never far away would say main appeal show due fact goe show dare forget pretti pictur paint mainstream audienc forget charm forget romanc oz mess around first episod ever saw struck nasti surreal say readi watch develop tast oz got accustom high level graphic violenc violenc injustic crook guard sold nickel inmat kill order get away well manner middl class inmat turn prison bitch due lack street skill prison experi watch oz may becom comfort uncomfort view that get touch darker side'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c436d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentiment to 1 for positive, 0 for negative\n",
    "label_encoder = LabelEncoder()\n",
    "df['sentiment'] = label_encoder.fit_transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4869976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_size = 5000  # ou toute autre taille que vous souhaitez\n",
    "df_subset = df.sample(subset_size, random_state=42)\n",
    "\n",
    "# Utiliser le sous-ensemble pour l'entraÃ®nement\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_subset['review'], df_subset['sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26d58eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Text Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80b029f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: LogisticRegression\n",
      "Best Model Accuracy: 0.854\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'SVM': SVC(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    # Add more models as needed\n",
    "}\n",
    "\n",
    "mlflow.set_experiment(\"scikit_learn_imdb\")\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "\n",
    "for name, model in models.items():\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        model.fit(X_train_vectorized, y_train)\n",
    "        y_pred = model.predict(X_test_vectorized)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "        # Log parameters and metrics to MLflow\n",
    "        mlflow.log_params({'model_type': type(model).__name__})\n",
    "        mlflow.log_metrics({'accuracy': accuracy})\n",
    "        \n",
    "        # Save the model as an MLflow artifact\n",
    "        mlflow.sklearn.log_model(model, f\"{name}_model\")\n",
    "\n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'accuracy': accuracy,\n",
    "            'classification_report': classification_rep\n",
    "        }\n",
    "\n",
    "        # Track the best model\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = model\n",
    "\n",
    "# Print the best model and its accuracy\n",
    "print(f\"Best Model: {type(best_model).__name__}\")\n",
    "print(f\"Best Model Accuracy: {best_accuracy}\")\n",
    "\n",
    "# End the MLflow run\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd02ee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = mlflow.sklearn.load_model(\"runs:/ebcad27735fb47aca144d631a25d7454/Logistic Regression_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba9f05d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into SVC model into ONNX format file\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "initial_type = [('float_input', FloatTensorType([None, X_train_vectorized.shape[1]]))]\n",
    "onx = convert_sklearn(log_reg_model, initial_types=initial_type)\n",
    "with open(\"outputs/log_reg_model.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2f5e646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./outputs/vectorizer.pkl', 'wb') as vectorizer_pkl:\n",
    "    pickle.dump(vectorizer, vectorizer_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc6e2ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
